{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIREN Training on PhotonSim Data - Example Workflow\n",
    "\n",
    "This notebook demonstrates how to use the refactored training modules to train JAXSiren on PhotonSim lookup tables.\n",
    "\n",
    "## Overview\n",
    "1. Load PhotonSim HDF5 lookup table\n",
    "2. Configure training parameters\n",
    "3. Choose training mode (resume from checkpoint or start fresh)\n",
    "4. Set up monitoring\n",
    "5. Train the model\n",
    "6. Analyze results with slice visualizations\n",
    "7. Test model predictions\n",
    "\n",
    "## Features\n",
    "- **Checkpoint Resume**: Automatically resumes from the latest checkpoint\n",
    "- **Fresh Start Option**: Clear all checkpoints and start from scratch\n",
    "- **Enhanced Visualizations**: Angular profiles and 2D comparisons for different energies\n",
    "- **Comprehensive Analysis**: Model performance evaluation and error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Get project paths correctly\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent  # diffCherenkov root (one level up from notebooks)\n",
    "photonsim_root = project_root.parent / 'PhotonSim'  # PhotonSim root\n",
    "\n",
    "# Add project paths\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'tools'))\n",
    "\n",
    "print(f\"Current dir: {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PhotonSim root: {photonsim_root}\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"Project root exists: {project_root.exists()}\")\n",
    "print(f\"Siren dir exists: {(project_root / 'siren').exists()}\")\n",
    "print(f\"Training dir exists: {(project_root / 'siren' / 'training').exists()}\")\n",
    "print(f\"PhotonSim root exists: {photonsim_root.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the refactored training modules with fallback strategies\n",
    "print(\"ðŸ“¦ Importing training modules...\")\n",
    "\n",
    "imported_successfully = False\n",
    "\n",
    "try:\n",
    "    # Strategy 1: Try standard package import\n",
    "    from siren.training import (\n",
    "        SIRENTrainer, \n",
    "        TrainingConfig, \n",
    "        PhotonSimDataset,\n",
    "        TrainingMonitor,\n",
    "        TrainingAnalyzer,\n",
    "        LiveTrainingCallback\n",
    "    )\n",
    "    print(\"âœ… Imported from siren.training package\")\n",
    "    imported_successfully = True\n",
    "    \n",
    "except ImportError as e1:\n",
    "    print(f\"âŒ Package import failed: {e1}\")\n",
    "    print(\"ðŸ”„ Trying direct module imports...\")\n",
    "    \n",
    "    try:\n",
    "        # Strategy 2: Add siren directory to path and import training module\n",
    "        siren_path = project_root / 'siren'\n",
    "        if str(siren_path) not in sys.path:\n",
    "            sys.path.insert(0, str(siren_path))\n",
    "        \n",
    "        from training import (\n",
    "            SIRENTrainer, \n",
    "            TrainingConfig, \n",
    "            PhotonSimDataset,\n",
    "            TrainingMonitor,\n",
    "            TrainingAnalyzer,\n",
    "            LiveTrainingCallback\n",
    "        )\n",
    "        print(\"âœ… Imported from training module directly\")\n",
    "        imported_successfully = True\n",
    "        \n",
    "    except ImportError as e2:\n",
    "        print(f\"âŒ Direct module import failed: {e2}\")\n",
    "        print(\"ðŸ”§ Trying manual imports from individual files...\")\n",
    "        \n",
    "        try:\n",
    "            # Strategy 3: Import from individual module files\n",
    "            training_path = project_root / 'siren' / 'training'\n",
    "            if str(training_path) not in sys.path:\n",
    "                sys.path.insert(0, str(training_path))\n",
    "            \n",
    "            from trainer import SIRENTrainer, TrainingConfig\n",
    "            from dataset import PhotonSimDataset\n",
    "            from monitor import TrainingMonitor, LiveTrainingCallback\n",
    "            from analyzer import TrainingAnalyzer\n",
    "            \n",
    "            print(\"âœ… Manual imports from individual files successful\")\n",
    "            imported_successfully = True\n",
    "            \n",
    "        except ImportError as e3:\n",
    "            print(f\"âŒ Manual import failed: {e3}\")\n",
    "            print(\"\\nðŸš¨ All import strategies failed!\")\n",
    "            print(\"Please check:\")\n",
    "            print(f\"  1. Current working directory: {Path.cwd()}\")\n",
    "            print(f\"  2. Project root: {project_root}\")\n",
    "            print(f\"  3. Siren directory exists: {(project_root / 'siren').exists()}\")\n",
    "            print(f\"  4. Training directory exists: {(project_root / 'siren' / 'training').exists()}\")\n",
    "            raise ImportError(\"Could not import training modules with any strategy\")\n",
    "\n",
    "if imported_successfully:\n",
    "    print(\"âœ… All training modules imported successfully!\")\n",
    "    print(\"ðŸš€ Ready to start training workflow\")\n",
    "else:\n",
    "    raise ImportError(\"Failed to import training modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load PhotonSim Data\n",
    "\n",
    "Load the HDF5 lookup table created in PhotonSim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the PhotonSim HDF5 lookup table\n",
    "h5_path = photonsim_root / 'output' / 'photon_lookup_table.h5'\n",
    "\n",
    "# Check if file exists\n",
    "if not h5_path.exists():\n",
    "    print(f\"âŒ HDF5 file not found at {h5_path}\")\n",
    "    print(\"Please run the PhotonSim table generation first:\")\n",
    "    print(\"  cd ../PhotonSim\")\n",
    "    print(\"  python tools/table_generation/create_density_3d_table.py --data-dir data/mu-\")\n",
    "else:\n",
    "    print(f\"âœ“ Found PhotonSim HDF5 file: {h5_path}\")\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = PhotonSimDataset(h5_path, val_split=0.1)\n",
    "    \n",
    "    print(f\"\\nDataset info:\")\n",
    "    print(f\"  Data type: {dataset.data_type}\")\n",
    "    print(f\"  Total samples: {len(dataset.data['inputs']):,}\")\n",
    "    print(f\"  Train samples: {len(dataset.train_indices):,}\")\n",
    "    print(f\"  Val samples: {len(dataset.val_indices):,}\")\n",
    "    print(f\"  Energy range: {dataset.energy_range[0]:.0f}-{dataset.energy_range[1]:.0f} MeV\")\n",
    "    print(f\"  Angle range: {np.degrees(dataset.angle_range[0]):.1f}-{np.degrees(dataset.angle_range[1]):.1f} degrees\")\n",
    "    print(f\"  Distance range: {dataset.distance_range[0]:.0f}-{dataset.distance_range[1]:.0f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Training Parameters\n",
    "\n",
    "Set up the training configuration using the `TrainingConfig` dataclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training configuration with PATIENCE-BASED learning rate scheduling\n",
    "config = TrainingConfig(\n",
    "    # Model architecture\n",
    "    hidden_features=256,\n",
    "    hidden_layers=4,\n",
    "    w0=30.0,\n",
    "    \n",
    "    # Training parameters\n",
    "    learning_rate=1e-4,        # Start here, let patience reduce it intelligently\n",
    "    weight_decay=1e-5,         # Regularization for stability\n",
    "    batch_size=8192,           # Smaller batches for better gradients\n",
    "    num_steps=10000,           # Enough steps to see patience in action\n",
    "    \n",
    "    # PATIENCE-BASED SCHEDULER (much better than fixed intervals!)\n",
    "    use_patience_scheduler=True,\n",
    "    patience=500,               # Reduce LR after 10 evals with no improvement  \n",
    "    lr_reduction_factor=0.5,   # Cut LR in half when triggered\n",
    "    min_lr=1e-7,              # Don't go below this\n",
    "    \n",
    "    # Stability features\n",
    "    optimizer='adamw',         # AdamW with built-in weight decay\n",
    "    grad_clip_norm=1.0,       # Prevent gradient explosions\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    log_every=50,\n",
    "    val_every=100,            # Check patience every 100 steps\n",
    "    checkpoint_every=1000,\n",
    "    \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"ðŸ§  FIXED Training Configuration with Patience:\")\n",
    "print(f\"  â€¢ Initial LR: {config.learning_rate:.2e}\")\n",
    "print(f\"  â€¢ Patience: {config.patience} evaluations\")\n",
    "print(f\"  â€¢ LR reduction: Ã—{config.lr_reduction_factor} when triggered\")\n",
    "print(f\"  â€¢ Minimum LR: {config.min_lr:.2e}\")\n",
    "print(f\"  â€¢ Validation every: {config.val_every} steps\")\n",
    "print(f\"  â€¢ Optimizer: {config.optimizer.upper()} with gradient clipping\")\n",
    "print(\"\\nðŸ“ˆ How it works:\")\n",
    "print(\"  â†’ LR stays constant while validation loss improves\")\n",
    "print(\"  â†’ After 10 evaluations with no improvement â†’ LR Ã· 2\")\n",
    "print(\"  â†’ Only updates LR when needed (not every step!)\")\n",
    "print(\"  â†’ Much faster training with adaptive LR!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Mode Selection\n",
    "\n",
    "Choose whether to resume from existing checkpoint or start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training mode configuration\n",
    "START_FRESH = True  # Set to True to start from scratch, False to resume from checkpoint\n",
    "\n",
    "# Set up output directory\n",
    "output_dir = Path('output') / 'photonsim_siren_training'\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Directory exists: {output_dir.exists()}\")\n",
    "\n",
    "# Check for existing checkpoints\n",
    "existing_checkpoints = list(output_dir.glob('*.npz'))\n",
    "existing_history = output_dir / 'training_history.json'\n",
    "\n",
    "if existing_checkpoints or existing_history.exists():\n",
    "    print(f\"\\nðŸ” Found existing training data:\")\n",
    "    if existing_history.exists():\n",
    "        import json\n",
    "        with open(existing_history, 'r') as f:\n",
    "            history = json.load(f)\n",
    "            if history.get('step'):\n",
    "                last_step = max(history['step'])\n",
    "                print(f\"  - Training history up to step {last_step}\")\n",
    "    \n",
    "    for checkpoint in existing_checkpoints:\n",
    "        print(f\"  - Checkpoint: {checkpoint.name}\")\n",
    "    \n",
    "    if START_FRESH:\n",
    "        print(f\"\\nðŸ”„ START_FRESH=True: Will clear existing data and start from scratch\")\n",
    "    else:\n",
    "        print(f\"\\nâ–¶ï¸  START_FRESH=False: Will resume from latest checkpoint\")\n",
    "else:\n",
    "    print(f\"\\nâœ¨ No existing training data found. Starting fresh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Trainer and Monitor\n",
    "\n",
    "Create the trainer and set up monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer with resume option\n",
    "trainer = SIRENTrainer(\n",
    "    dataset=dataset,\n",
    "    config=config,\n",
    "    output_dir=output_dir,\n",
    "    resume_from_checkpoint=not START_FRESH  # Resume unless starting fresh\n",
    ")\n",
    "\n",
    "# Clear checkpoints if starting fresh\n",
    "if START_FRESH:\n",
    "    print(\"ðŸ§¹ Clearing existing checkpoints...\")\n",
    "    trainer.clear_checkpoints()\n",
    "    print(\"âœ… Starting with clean slate\")\n",
    "\n",
    "print(f\"âœ“ Trainer initialized\")\n",
    "print(f\"âœ“ Output directory: {output_dir}\")\n",
    "print(f\"âœ“ JAX device: {trainer.device}\")\n",
    "\n",
    "# Check if we're resuming\n",
    "if trainer.start_step > 0:\n",
    "    print(f\"âœ“ Resuming from step {trainer.start_step}\")\n",
    "    print(f\"âœ“ Training history loaded with {len(trainer.history['train_loss'])} entries\")\n",
    "else:\n",
    "    print(f\"âœ“ Starting fresh training from step 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up monitoring with live plotting\n",
    "monitor = TrainingMonitor(output_dir, live_plotting=True)\n",
    "\n",
    "# Create live callback for real-time plot updates during training\n",
    "live_callback = LiveTrainingCallback(\n",
    "    monitor, \n",
    "    update_every=50,   # Update data every 50 steps\n",
    "    plot_every=200     # Update plots every 200 steps\n",
    ")\n",
    "\n",
    "# Add callback to trainer for live monitoring\n",
    "trainer.add_callback(live_callback)\n",
    "\n",
    "print(\"âœ“ Monitoring setup complete\")\n",
    "print(\"âœ“ Live plotting enabled - plots will update during training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"Starting SIREN training...\")\n",
    "history = trainer.train()\n",
    "\n",
    "print(\"\\nâœ“ Training completed!\")\n",
    "print(f\"Final train loss: {history['train_loss'][-1]:.6f}\")\n",
    "if history['val_loss']:\n",
    "    print(f\"Final val loss: {history['val_loss'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "Start training with live monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "fig = trainer.plot_training_history(save_path=output_dir / 'final_training_progress.png')\n",
    "plt.show()\n",
    "\n",
    "# Also plot monitoring dashboard\n",
    "print(\"\\nðŸ“Š Training Progress Dashboard:\")\n",
    "monitor_fig = monitor.plot_progress(save_path=output_dir / 'training_dashboard.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = trainer.plot_training_history(save_path=output_dir / 'final_training_progress.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Model Performance\n",
    "\n",
    "Use the analyzer to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = TrainingAnalyzer(trainer, dataset)\n",
    "\n",
    "# Evaluate model\n",
    "evaluation_results = analyzer.evaluate_model(n_samples=50000, splits=['train', 'val'])\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "for split, results in evaluation_results.items():\n",
    "    metrics = results['metrics']\n",
    "    print(f\"\\n{split.upper()} Split:\")\n",
    "    print(f\"  RÂ²: {metrics['r2']:.6f}\")\n",
    "    print(f\"  RMSE: {metrics['rmse']:.6f}\")\n",
    "    print(f\"  MAE: {metrics['mae']:.6f}\")\n",
    "    print(f\"  Relative Error: {metrics['relative_error']:.6f}\")\n",
    "    print(f\"  Correlation: {metrics['correlation']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze error patterns\n",
    "error_analysis = analyzer.analyze_error_patterns(split='val', n_samples=20000)\n",
    "\n",
    "print(\"\\nError Analysis:\")\n",
    "for analysis_name, analysis_data in error_analysis.items():\n",
    "    if 'dimension_name' in analysis_data:\n",
    "        dim_name = analysis_data['dimension_name']\n",
    "        dim_range = analysis_data['dimension_range']\n",
    "        avg_error = np.mean(analysis_data['mean_errors'])\n",
    "        print(f\"  {dim_name}: range {dim_range[0]:.2f}-{dim_range[1]:.2f}, avg error: {avg_error:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slice comparison plots\n",
    "fig_slices = analyzer.plot_lookup_table_slices(save_path=output_dir / 'lookup_table_slices.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Lookup Table Slice Comparisons\n",
    "\n",
    "Create slice visualizations comparing lookup table expectations vs SIREN model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Model Predictions\n",
    "\n",
    "Test the model on specific energy/angle/distance combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export analysis results\n",
    "analyzer.export_results(output_dir / 'analysis_results.json')\n",
    "\n",
    "# Export monitoring data\n",
    "monitor.export_data(output_dir / 'monitoring_data.json')\n",
    "\n",
    "print(\"âœ“ Results exported to:\")\n",
    "print(f\"  Model checkpoint: {output_dir / 'final_model.npz'}\")\n",
    "print(f\"  Training config: {output_dir / 'config.json'}\")\n",
    "print(f\"  Training history: {output_dir / 'training_history.json'}\")\n",
    "print(f\"  Analysis results: {output_dir / 'analysis_results.json'}\")\n",
    "print(f\"  Monitoring data: {output_dir / 'monitoring_data.json'}\")\n",
    "print(f\"  Plots: {output_dir / '*.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Model Summary\n",
    "\n",
    "Display a final summary of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Save Results\n",
    "\n",
    "Export analysis results and model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Model Summary\n",
    "\n",
    "Display a final summary of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final summary\n",
    "summary = monitor.get_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  Hidden features: {config.hidden_features}\")\n",
    "print(f\"  Hidden layers: {config.hidden_layers}\")\n",
    "print(f\"  SIREN frequency (w0): {config.w0}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Learning rate: {config.learning_rate:.2e}\")\n",
    "print(f\"  Batch size: {config.batch_size:,}\")\n",
    "print(f\"  Total steps: {config.num_steps:,}\")\n",
    "print(f\"  Weight decay: {config.weight_decay:.2e}\")\n",
    "\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"  Total samples: {len(dataset.data['inputs']):,}\")\n",
    "print(f\"  Training samples: {len(dataset.train_indices):,}\")\n",
    "print(f\"  Validation samples: {len(dataset.val_indices):,}\")\n",
    "print(f\"  Energy range: {dataset.energy_range[0]:.0f}-{dataset.energy_range[1]:.0f} MeV\")\n",
    "\n",
    "print(f\"\\nFinal Performance:\")\n",
    "if 'val' in evaluation_results:\n",
    "    val_metrics = evaluation_results['val']['metrics']\n",
    "    print(f\"  Validation RÂ²: {val_metrics['r2']:.6f}\")\n",
    "    print(f\"  Validation RMSE: {val_metrics['rmse']:.6f}\")\n",
    "    print(f\"  Validation MAE: {val_metrics['mae']:.6f}\")\n",
    "    print(f\"  Relative Error: {val_metrics['relative_error']:.6f}\")\n",
    "    \n",
    "print(f\"\\nOutput Directory: {output_dir}\")\n",
    "print(\"\\nâœ“ Training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
