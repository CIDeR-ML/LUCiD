{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed4cda-abb6-48f5-b23f-7f2e2e6e5e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "training_path = Path('../siren/training')\n",
    "sys.path.append(str(training_path))\n",
    "\n",
    "from tools.siren import *\n",
    "from inference import SIRENPredictor\n",
    "\n",
    "from tools.simulation import create_photonsim_siren_grid\n",
    "from tools.generate import generate_random_cone_vectors, normalize, photonsim_differentiable_get_rays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d5bd6-641a-4bb4-ab89-b7ed888ddef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_path = Path('../notebooks/output/photonsim_siren_training/trained_model/photonsim_siren')\n",
    "photonsim_predictor = SIRENPredictor(model_base_path)\n",
    "table_data = create_photonsim_siren_grid(photonsim_predictor, 500)\n",
    "\n",
    "# Set up simulation parameters (same as original)\n",
    "origin = jnp.array([0.5, 0.0, -0.5])\n",
    "direction = jnp.array([1.0, -1.0, 0.2])\n",
    "Nphot = 1_000_000\n",
    "key = random.PRNGKey(0)\n",
    "energy = 500\n",
    "model_params = photonsim_predictor.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abb90f-5fe5-41e3-87d7-649efdb2c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def benchmark_photon_counts(photon_counts, origin, direction, energy, table_data, model_params, key):\n",
    "    \"\"\"\n",
    "    Benchmark the new_differentiable_get_rays function across different photon counts\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'photon_counts': [],\n",
    "        'mean_times': [],\n",
    "        'std_times': [],\n",
    "        'all_times': []\n",
    "    }\n",
    "    \n",
    "    print(\"Benchmarking photon counts:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, Nphot in enumerate(photon_counts):\n",
    "        print(f\"Testing {Nphot:,} photons ({i+1}/{len(photon_counts)})...\")\n",
    "        \n",
    "        # Warmup run (important for JAX compiled functions)\n",
    "        #if i == 0:  # Only warmup on first iteration\n",
    "        #    #print(\"  Performing warmup...\")\n",
    "        _ = photonsim_differentiable_get_rays(origin, direction, energy, Nphot, table_data, model_params, key)\n",
    "        \n",
    "        # Use IPython's timeit magic to get detailed timing\n",
    "        timing_result = %timeit -n 100 -r 2 -o ray_vectors, ray_origins, photon_weights = photonsim_differentiable_get_rays(origin, direction, energy, Nphot, table_data, model_params, key)\n",
    "        \n",
    "        # Extract metrics\n",
    "        mean_time = timing_result.average\n",
    "        std_time = timing_result.stdev\n",
    "        all_runs = timing_result.all_runs\n",
    "        \n",
    "        # Store results\n",
    "        results['photon_counts'].append(Nphot)\n",
    "        results['mean_times'].append(mean_time)\n",
    "        results['std_times'].append(std_time)\n",
    "        results['all_times'].append(all_runs)\n",
    "        \n",
    "        print(f\"  Mean: {mean_time:.4f}s ± {std_time:.4f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define photon count range (10 points from ~0 to 5 million)\n",
    "# Starting from 100,000 instead of 0 to avoid edge cases\n",
    "photon_counts = [1_000, 10_000, 50_000, 100_000, 200_000, 300_000, 400_000, 500_000, 1_000_000, 2_000_000, 3_000_000, 4_000_000, 5_000_000]#np.logspace(5, np.log10(5_00_000), 5, dtype=int)\n",
    "print(\"Photon counts to test:\", [f\"{n:,}\" for n in photon_counts])\n",
    "\n",
    "# Run the benchmark\n",
    "results = benchmark_photon_counts(photon_counts, origin, direction, energy, table_data, model_params, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bdcbfa-d242-49e6-a9ed-925fe744ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['text.usetex'] = False\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "figsize = (6,4)\n",
    "\n",
    "# Convert to numpy arrays for easier plotting\n",
    "photon_counts = np.array(results['photon_counts'])\n",
    "mean_times = np.array(results['mean_times'])\n",
    "std_times = np.array(results['std_times'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "# Main plot with error bars\n",
    "plt.errorbar(photon_counts / 1e6, mean_times, yerr=std_times, \n",
    "             marker='o', markersize=8, capsize=5, capthick=2, \n",
    "             linewidth=2, label='Execution Time', zorder=-1, color='navy')\n",
    "\n",
    "plt.xlabel('Number of Photons (Millions)')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Performance vs Number of Photons')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Add some styling\n",
    "plt.tight_layout()\n",
    "\n",
    "# Optional: Add a linear fit to see scaling behavior\n",
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(photon_counts, mean_times)\n",
    "fit_line = slope * photon_counts + intercept\n",
    "plt.plot(photon_counts / 1e6, fit_line, '--', alpha=0.7, color='darkorange', lw=2, \n",
    "         label=f'Linear fit (R² = {r_value**2:.3f})')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Additional analysis: throughput plot\n",
    "plt.figure(figsize=figsize)\n",
    "throughput = (photon_counts / 1e6) / mean_times\n",
    "plt.plot(photon_counts / 1e6, throughput, 'o-', linewidth=2, markersize=8, color='navy')\n",
    "plt.xlabel('Number of Photons (Millions)')\n",
    "plt.ylabel('Throughput (Million Photons/Second)')\n",
    "plt.title('Throughput vs Number of Photons')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Photons':<12} {'Mean Time (s)':<15} {'Std Dev (s)':<12} {'Throughput (M/s)':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (n_phot, mean_t, std_t) in enumerate(zip(photon_counts, mean_times, std_times)):\n",
    "    throughput = (n_phot / 1e6) / mean_t\n",
    "    print(f\"{n_phot:<12,} {mean_t:<15.4f} {std_t:<12.4f} {throughput:<15.2f}\")\n",
    "\n",
    "print(f\"\\nLinear scaling coefficient: {slope:.2e} s/photon\")\n",
    "print(f\"Base overhead: {intercept:.4f} s\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b08fde-de52-49a2-8878-e37a142375a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from tools.propagate import create_photon_propagator\n",
    "from tools.geometry import generate_detector\n",
    "from tools.utils import generate_random_point_inside_cylinder, generate_random_params\n",
    "from tools.losses import compute_simplified_loss\n",
    "from tools.simulation import setup_event_simulator\n",
    "\n",
    "# Configuration\n",
    "default_json_filename = '../config/IWCD_geom_config.json'\n",
    "detector = generate_detector(default_json_filename)\n",
    "detector_points = jnp.array(detector.all_points)\n",
    "\n",
    "# Benchmarking parameters\n",
    "K_VALUES = [1, 2, 3, 4]\n",
    "N_VALUES = [100000, 250000]#, 500000, 750000, 1000000, 1500000, 2000000]\n",
    "WARMUP_RUNS = 10\n",
    "TIMING_RUNS = 100\n",
    "\n",
    "def benchmark_simulation(is_calibration=False):\n",
    "    \"\"\"Benchmark simulation for different N and K values\"\"\"\n",
    "    results = {k: {'N': [], 'mean_time': [], 'std_time': []} for k in K_VALUES}\n",
    "\n",
    "    print(\"Benchmarking simulation performance...\")\n",
    "\n",
    "    for K in K_VALUES:\n",
    "        print(f\"\\nK = {K}\")\n",
    "\n",
    "        for Nphot in N_VALUES:\n",
    "            print(f\"  N = {Nphot:,}\")\n",
    "\n",
    "            # Setup simulator\n",
    "            simulate_event = jit(setup_event_simulator(\n",
    "                default_json_filename, Nphot, temperature=None, K=K, is_calibration=is_calibration\n",
    "            ))\n",
    "\n",
    "            # Initial key\n",
    "            key = jax.random.PRNGKey(42)\n",
    "\n",
    "            # Warmup\n",
    "            for _ in range(WARMUP_RUNS):\n",
    "                key, subkey = jax.random.split(key)\n",
    "                # Generate new position each time\n",
    "                source_origin = generate_random_point_inside_cylinder(subkey, r=4, h=6)\n",
    "                other_params = (source_origin, 1000)\n",
    "                track_params = (\n",
    "                    jnp.array(800.0, dtype=jnp.float32),\n",
    "                    jnp.array([0.0, 0.0, 0.0], dtype=jnp.float32),\n",
    "                    jnp.array([jnp.pi/3, jnp.pi/4], dtype=jnp.float32)\n",
    "                )\n",
    "                \n",
    "                if is_calibration == False:\n",
    "                    other_params = track_params\n",
    "                \n",
    "                detector_params = (\n",
    "                    jnp.array(4.), jnp.array(0.2), jnp.array(6.), jnp.array(0.001)\n",
    "                )\n",
    "                \n",
    "                key, subkey = jax.random.split(key)\n",
    "                result = simulate_event(other_params, detector_params, subkey)\n",
    "                jax.tree.map(lambda x: x.block_until_ready(), result)\n",
    "\n",
    "            # Timing\n",
    "            times = []\n",
    "            for _ in range(TIMING_RUNS):\n",
    "                key, subkey = jax.random.split(key)\n",
    "                # Generate new position each time\n",
    "                source_origin = generate_random_point_inside_cylinder(subkey, r=4, h=6)\n",
    "                other_params = (source_origin, 1000)\n",
    "                track_params = (\n",
    "                    jnp.array(800.0, dtype=jnp.float32),\n",
    "                    jnp.array([0.0, 0.0, 0.0], dtype=jnp.float32),\n",
    "                    jnp.array([jnp.pi/3, jnp.pi/4], dtype=jnp.float32)\n",
    "                )\n",
    "                \n",
    "                if is_calibration == False:\n",
    "                    other_params = track_params\n",
    "                \n",
    "                detector_params = (\n",
    "                    jnp.array(4.), jnp.array(0.2), jnp.array(6.), jnp.array(0.001)\n",
    "                )\n",
    "            \n",
    "                key, subkey = jax.random.split(key)\n",
    "                start = time.time()\n",
    "                result = simulate_event(other_params, detector_params, subkey)\n",
    "                jax.tree.map(lambda x: x.block_until_ready(), result)\n",
    "                times.append(time.time() - start)\n",
    "\n",
    "            results[K]['N'].append(Nphot)\n",
    "            results[K]['mean_time'].append(np.mean(times))\n",
    "            results[K]['std_time'].append(np.std(times))\n",
    "\n",
    "    return results\n",
    "\n",
    "def benchmark_gradient(is_calibration=False):\n",
    "    \"\"\"Benchmark gradient computation for source and detector parameters\"\"\"\n",
    "    results = {k: {'N': [], 'mean_time': [], 'std_time': []} for k in K_VALUES}\n",
    "\n",
    "    print(\"\\n\\nBenchmarking gradient computation...\")\n",
    "\n",
    "    # Generate true data once with fixed N\n",
    "    Nphot_true = 100000\n",
    "    key = jax.random.PRNGKey(42)\n",
    "\n",
    "    source_origin = generate_random_point_inside_cylinder(key, r=4, h=6)\n",
    "    other_params = (source_origin, 1000)\n",
    "    track_params = (\n",
    "        jnp.array(800.0, dtype=jnp.float32),\n",
    "        jnp.array([0.0, 0.0, 0.0], dtype=jnp.float32),\n",
    "        jnp.array([jnp.pi/3, jnp.pi/4], dtype=jnp.float32)\n",
    "    )\n",
    "    \n",
    "    if is_calibration == False:\n",
    "        other_params = track_params\n",
    "    \n",
    "    detector_params = (\n",
    "        jnp.array(4.), jnp.array(0.2), jnp.array(6.), jnp.array(0.001)\n",
    "    )\n",
    "\n",
    "    # Generate true data with fixed simulator\n",
    "    simulate_true = setup_event_simulator(\n",
    "        default_json_filename, Nphot_true, temperature=None, K=2, is_calibration=is_calibration\n",
    "    )\n",
    "    key, subkey = jax.random.split(key)\n",
    "    true_data = jax.lax.stop_gradient(simulate_true(other_params, detector_params, subkey))\n",
    "\n",
    "    for K in K_VALUES:\n",
    "        print(f\"\\nK = {K}\")\n",
    "\n",
    "        for Nphot in N_VALUES:\n",
    "            print(f\"  N = {Nphot:,}\")\n",
    "\n",
    "            # Setup simulator for this N\n",
    "            simulate_event = setup_event_simulator(\n",
    "                default_json_filename, Nphot, temperature=None, K=K, is_calibration=is_calibration\n",
    "            )\n",
    "\n",
    "            # Create loss and gradient function for both source and detector params\n",
    "            @jit\n",
    "            def loss_and_grad_fn(other_params, detector_params):\n",
    "                def loss_fn(s_origin, d_params):\n",
    "                    #source_params = (s_origin, 1000)\n",
    "                    simulated_data = simulate_event(other_params, d_params, key)\n",
    "                    return compute_simplified_loss(detector_points, *true_data, *simulated_data, lambda_time=0.0)\n",
    "                return value_and_grad(loss_fn, argnums=(0, 1))(source_origin, detector_params)\n",
    "\n",
    "            # Warmup\n",
    "            for i in range(WARMUP_RUNS):\n",
    "                # Generate new position each time\n",
    "                key, subkey = jax.random.split(key)\n",
    "                #test_origin = generate_random_point_inside_cylinder(subkey, r=4, h=6)\n",
    "\n",
    "                source_origin = generate_random_point_inside_cylinder(key, r=4, h=6)\n",
    "                other_params = (source_origin, 1000)\n",
    "                \n",
    "                if is_calibration == False:\n",
    "                    other_params = generate_random_params(key)\n",
    "                \n",
    "                loss_val, (grad_source, grad_detector) = loss_and_grad_fn(other_params, detector_params)\n",
    "                jax.tree.map(lambda x: x.block_until_ready(), (loss_val, grad_source, grad_detector))\n",
    "\n",
    "            # Timing\n",
    "            times = []\n",
    "            for i in range(TIMING_RUNS):\n",
    "                # Generate new position each time\n",
    "                key, subkey = jax.random.split(key)\n",
    "                #test_origin = generate_random_point_inside_cylinder(subkey, r=4, h=6)\n",
    "\n",
    "                source_origin = generate_random_point_inside_cylinder(key, r=4, h=6)\n",
    "                other_params = (source_origin, 1000)\n",
    "                \n",
    "                if is_calibration == False:\n",
    "                    other_params = generate_random_params(key)\n",
    "                \n",
    "                start = time.time()\n",
    "                loss_val, (grad_source, grad_detector) = loss_and_grad_fn(other_params, detector_params)\n",
    "                jax.tree.map(lambda x: x.block_until_ready(), (loss_val, grad_source, grad_detector))\n",
    "                times.append(time.time() - start)\n",
    "\n",
    "            results[K]['N'].append(Nphot)\n",
    "            results[K]['mean_time'].append(np.mean(times))\n",
    "            results[K]['std_time'].append(np.std(times))\n",
    "\n",
    "    return results\n",
    "\n",
    "sim_results_full = benchmark_simulation(is_calibration=False)\n",
    "grad_results_full = benchmark_gradient(is_calibration=False)\n",
    "\n",
    "sim_results_calib = benchmark_simulation(is_calibration=True)\n",
    "grad_results_calib = benchmark_gradient(is_calibration=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY CALIBRATION\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nSimulation times (milliseconds):\")\n",
    "for K in K_VALUES:\n",
    "    print(f\"\\nK = {K}:\")\n",
    "    for i, N in enumerate(sim_results_calib[K]['N']):\n",
    "        mean_ms = sim_results_calib[K]['mean_time'][i] * 1000\n",
    "        std_ms = sim_results_calib[K]['std_time'][i] * 1000\n",
    "        print(f\"  N = {N:>9,}: {mean_ms:.2f} ± {std_ms:.2f} ms\")\n",
    "\n",
    "print(\"\\nGradient computation times (milliseconds):\")\n",
    "for K in K_VALUES:\n",
    "    print(f\"\\nK = {K}:\")\n",
    "    for i, N in enumerate(grad_results_calib[K]['N']):\n",
    "        mean_ms = grad_results_calib[K]['mean_time'][i] * 1000\n",
    "        std_ms = grad_results_calib[K]['std_time'][i] * 1000\n",
    "        print(f\"  N = {N:>9,}: {mean_ms:.2f} ± {std_ms:.2f} ms\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY FULL\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nSimulation times (milliseconds):\")\n",
    "for K in K_VALUES:\n",
    "    print(f\"\\nK = {K}:\")\n",
    "    for i, N in enumerate(sim_results_full[K]['N']):\n",
    "        mean_ms = sim_results_full[K]['mean_time'][i] * 1000\n",
    "        std_ms = sim_results_full[K]['std_time'][i] * 1000\n",
    "        print(f\"  N = {N:>9,}: {mean_ms:.2f} ± {std_ms:.2f} ms\")\n",
    "\n",
    "print(\"\\nGradient computation times (milliseconds):\")\n",
    "for K in K_VALUES:\n",
    "    print(f\"\\nK = {K}:\")\n",
    "    for i, N in enumerate(grad_results_full[K]['N']):\n",
    "        mean_ms = grad_results_full[K]['mean_time'][i] * 1000\n",
    "        std_ms = grad_results_full[K]['std_time'][i] * 1000\n",
    "        print(f\"  N = {N:>9,}: {mean_ms:.2f} ± {std_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44659f2-337d-43e8-9d8c-379dc698a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "def plot_results(sim_results, grad_results):\n",
    "    \"\"\"Plot both simulation and gradient results\"\"\"\n",
    "\n",
    "    # Use same colors for both plots\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(K_VALUES)))\n",
    "\n",
    "    # Simulation timing plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    for i, K in enumerate(K_VALUES):\n",
    "        N = np.array(sim_results[K]['N'])\n",
    "        mean_time = np.array(sim_results[K]['mean_time']) * 1000  # Convert to ms\n",
    "        std_time = np.array(sim_results[K]['std_time']) * 1000   # Convert to ms\n",
    "\n",
    "        plt.plot(N, mean_time, 'o-', color=colors[i], label=f'K={K}')\n",
    "        plt.fill_between(N, mean_time - std_time, mean_time + std_time, alpha=0.3, color=colors[i])\n",
    "\n",
    "    plt.xlabel('Number of Photons (N)')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.title('Simulation Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../plots/simulation_timing.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Gradient timing plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    for i, K in enumerate(K_VALUES):\n",
    "        N = np.array(grad_results[K]['N'])\n",
    "        mean_time = np.array(grad_results[K]['mean_time']) * 1000  # Convert to ms\n",
    "        std_time = np.array(grad_results[K]['std_time']) * 1000   # Convert to ms\n",
    "\n",
    "        plt.plot(N, mean_time, 'o-', color=colors[i], label=f'K={K}')\n",
    "        plt.fill_between(N, mean_time - std_time, mean_time + std_time, alpha=0.3, color=colors[i])\n",
    "\n",
    "    plt.xlabel('Number of Photons (N)')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.title('Gradient Computation Performance\\n(Source + Detector Parameters)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../plots/gradient_timing.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4a370-9948-42a5-82ed-d27e466cc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(sim_results_calib, grad_results_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ccfe2-3a36-41dc-89c4-080190765ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(sim_results_full, grad_results_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
